{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14c3ad4",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "could not translate host name \"sph-pgsql01.spherelab.local\" to address: Unknown host\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m database\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#Подключение к БД\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m conn \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdatabase)\n\u001b[0;32m     13\u001b[0m cursor \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[0;32m     15\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpostgresql+psycopg2://\u001b[39m\u001b[38;5;132;01m{user}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{password}\u001b[39;00m\u001b[38;5;124m@\u001b[39m\u001b[38;5;132;01m{host}\u001b[39;00m\u001b[38;5;124m:5432/\u001b[39m\u001b[38;5;132;01m{database}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdatabase))\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m _connect(dsn, connection_factory\u001b[38;5;241m=\u001b[39mconnection_factory, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
      "\u001b[1;31mOperationalError\u001b[0m: could not translate host name \"sph-pgsql01.spherelab.local\" to address: Unknown host\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime as dt\n",
    "import psycopg2 as db\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Импорт парметров подключения к БД\n",
    "from config import database\n",
    "\n",
    "#Подключение к БД\n",
    "conn = db.connect(**database)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "engine = create_engine('postgresql+psycopg2://{user}:{password}@{host}:5432/{database}'.format(**database))\n",
    "\n",
    "# Функция для загрузки таблицы с информацией об АЦ\n",
    "def add_tanker_information_to_db(conn):\n",
    "    \n",
    "    query = \"select * from superset.kind_tanker_v\"\n",
    "\n",
    "    df_tanker = pd.read_sql_query(query, conn)\n",
    "    df_tanker.index = df_tanker.loc[:, 'tanker_name']\n",
    "    df_tanker = df_tanker[['petrol1', 'diesel', 'petrol2', 'petrol3']]\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "    return df_tanker\n",
    "\n",
    "#Применение функции\n",
    "df_tanker = add_tanker_information_to_db(conn)\n",
    "\n",
    "# Функция загрузки с БД таблицу с НСИ по всем резервуарам\n",
    "def get_rez_table(conn):\n",
    "\n",
    "    query = '''select pnpo_id as pnpo, azs_id as azs, rez_id as rez, rez_volume,\n",
    "                rez_ref.oil_type as oil_id,\n",
    "                oil_ref.name as oil_type, tanker_ref.name as kind_tanker\n",
    "                from superset.rez_ref  \n",
    "                left join superset.tanker_ref on tanker_ref.id_tanker=rez_ref.kind_tanker\n",
    "                left join superset.oil_ref on oil_ref.id_oil=rez_ref.oil_type\n",
    "                ORDER BY azs_id ASC'''\n",
    "\n",
    "    df_with_rez = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "    return df_with_rez\n",
    "\n",
    "# Применение функции \n",
    "df_with_rez = get_rez_table(conn)\n",
    "\n",
    "# Функция для загрузки таблицы с информацией о пистолетов\n",
    "def get_pump_df(conn):\n",
    "    \n",
    "    query = \"select * from superset.pump_ref order by pump_id\"\n",
    "\n",
    "    df_pump = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "    return df_pump\n",
    "\n",
    "#Применение функции\n",
    "df_pump = get_pump_df(conn)\n",
    "\n",
    "# Функция для загрузки таблицы с информацией о сменах\n",
    "def get_shift_df(conn):\n",
    "    \n",
    "    query = \"select * from superset.shift_ref order by shift_id\"\n",
    "\n",
    "    df_shift = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "    return df_shift\n",
    "\n",
    "#Применение функции\n",
    "df_shift = get_shift_df(conn)\n",
    "\n",
    "# Функция для загрузки таблицы с информацией о расписаниях по сменам\n",
    "def get_schedle_df(conn):\n",
    "    \n",
    "    query = \"select * from superset.schedle_shift_ref order by schedle_shift_id\"\n",
    "\n",
    "    df_schedle = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "    return df_schedle\n",
    "\n",
    "#Применение функции\n",
    "df_schedle = get_schedle_df(conn)\n",
    "\n",
    "#Применение функцииОбъединение двух таблиц по сменам\n",
    "df_shift_with_schedule = df_shift.merge(df_schedle, how='left', left_on='azs_id', right_on='azs_id')\n",
    "\n",
    "#Инициализация вводимых пользователем парметров\n",
    "print('Введите начало периода генерации данных в формате %d-%m-%Y %H:%M:%S')\n",
    "date_start = str(input())     #'01-05-2022 12:00:00' #VARRIBLE\n",
    "print('Введите окончание периода генерации данных в формате %d-%m-%Y %H:%M:%S')\n",
    "date_finish = str(input()) #VARRIBLE '06-05-2022 12:00:00'\n",
    "print('Введите общий процент дебалансов на одной АЗС')\n",
    "mutual_part_for_noise = 100#int(input()) \n",
    "mutual_part_for_noise = mutual_part_for_noise*0.01 # Variable\n",
    "print('Введите процент положительных дебалансов среди общих на одной АЗС')\n",
    "positive_part_for_noise = 50 #int(input()) \n",
    "positive_part_for_noise = positive_part_for_noise*0.01 # Variable\n",
    "print('Введите левую границу относительного отклонения положительных дебалансов')\n",
    "left_positive_border = 0#int(input()) \n",
    "left_positive_border = left_positive_border*0.01 # Variable\n",
    "print('Введите правую границу относительного отклонения положительных дебалансов')\n",
    "right_positive_border = 10#int(input()) \n",
    "right_positive_border = right_positive_border*0.01 # Variable\n",
    "print('Введите левую границу относительного отклонения отрицательных дебалансов')\n",
    "left_negative_border = 0#int(input()) \n",
    "left_negative_border = left_negative_border*0.01 # Variable\n",
    "print('Введите правую границу относительного отклонения отрицательных дебалансов')\n",
    "right_negative_border = 10#int(input()) \n",
    "right_negative_border = right_negative_border*0.01 # Variable\n",
    "print('Для какого количества АЗС Вы хотите сгенерировать данные')\n",
    "count_of_azs = int(input()) #\n",
    "\n",
    "# Здесь нужен цилк перебирающий все АЗС\n",
    "for azs_name in range(1, count_of_azs+1): #df_with_rez['azs'].unique():#\n",
    "\n",
    "    # Функция для перевода даты и фильтрация таблицы по АЗС\n",
    "    def prepare_start_data(azs_name, date_start, date_finish, df_shift_with_schedule, df_pump):\n",
    "\n",
    "        current_date = dt.datetime.strptime(date_start, '%d-%m-%Y %H:%M:%S')\n",
    "        finish_date = dt.datetime.strptime(date_finish, '%d-%m-%Y %H:%M:%S')\n",
    "        df_for_count_data = df_with_rez[df_with_rez['azs']==azs_name].reset_index(drop=True)\n",
    "        df_for_check_data = df_pump[df_pump['azs_id']==azs_name].reset_index(drop=True)\n",
    "        df_for_shift_data = df_shift_with_schedule[df_shift_with_schedule['azs_id']==azs_name].reset_index(drop=True)\n",
    "        return current_date, finish_date, df_for_count_data, df_for_check_data, df_for_shift_data\n",
    "\n",
    "    #Применение функции\n",
    "    current_date, finish_date, df_for_count_data, df_for_check_data, df_for_shift_data = prepare_start_data(azs_name, date_start, date_finish, df_shift_with_schedule, df_pump)\n",
    "\n",
    "    #Создание словарика для периодичности слива из Резервуара\n",
    "    def create_dict_for_data(df_for_count_data):\n",
    "        x = len(df_for_count_data)\n",
    "        x1 = 520\n",
    "        x2 = 259\n",
    "        x3 = 1309\n",
    "        dict_for_data = {'25000':x1, '50000':x2, '10000':x3}\n",
    "        return dict_for_data\n",
    "\n",
    "    #Примение функции\n",
    "    dict_for_data = create_dict_for_data(df_for_count_data)\n",
    "\n",
    "    #Инициализация начального состояния топлива в резервуаре\n",
    "    def generate_start_volume(azs_name, df_for_count_data):\n",
    "        matrix_sliv = np.zeros(shape=(len(df_for_count_data), 5), dtype=object)\n",
    "        #np.random.seed() #стоит добавить если хотим псевдо случайные числа\n",
    "        start_volume_in_rez = [round(np.random.uniform(0.1, 0.9)*df_for_count_data.loc[0,'rez_volume'],2)\\\n",
    "                          for _ in range(len(df_for_count_data))]\n",
    "        matrix_sliv[:, 0] = start_volume_in_rez\n",
    "        return matrix_sliv\n",
    "\n",
    "    #Применеие функции\n",
    "    matrix_sliv = generate_start_volume(azs_name, df_for_count_data)\n",
    "    #print(matrix_sliv)\n",
    "    # Создание словаря для чеков из 3-ех массивов: пистолете, сливов в литрах и времени слива\n",
    "    count_check = {0:[[],[],[]], 1:[[],[],[]], 2:[[],[],[]], 3:[[],[],[]], 4:[[],[],[]], 5:[[],[],[]]}\n",
    "    # Создаем переменную с началом смены\n",
    "    start_shift = dt.datetime(current_date.year, current_date.month, current_date.day,\\\n",
    "                              df_for_shift_data.loc[0, 'time_start_shift'].hour, 0)\\\n",
    "    - dt.timedelta(days=1) if current_date.hour < 6\\\n",
    "    else dt.datetime(current_date.year, current_date.month, current_date.day, 6, 0)\n",
    "    # Создание счетчика номеров смен\n",
    "    shift_num = 1\n",
    "    # Создание счетчика по количеству изменения номера смен\n",
    "    count_fact_shift = 1\n",
    "    # Создание матрицы для записи смен\n",
    "    matrix_shift = np.array([[shift_num, start_shift, 0],[shift_num, start_shift, 0]], dtype=object)\n",
    "    # Создание матрицы для записей результата сверки типа 4\n",
    "    matrix_type_4 = np.zeros(shape=(1, len(df_for_count_data)+2), dtype=object)\n",
    "\n",
    "    #Функция для создания словарика с состоянием по сливам и остаткам\n",
    "    def create_matrix_dict():\n",
    "        matrix_dict = {}\n",
    "        for i in range(matrix_sliv.shape[0]):\n",
    "                matrix_dict[i] = matrix_sliv[i,[0,2,3,4]].tolist()\n",
    "        return matrix_dict\n",
    "    #Примение функции\n",
    "    matrix_dict = create_matrix_dict()\n",
    "\n",
    "    #Инициализация начального состояния времени в чеках\n",
    "    count_check[0][1].append(current_date)\n",
    "    count_check[1][1].append(current_date)\n",
    "    count_check[2][1].append(current_date)\n",
    "    count_check[3][1].append(current_date)\n",
    "    count_check[4][1].append(current_date)\n",
    "    count_check[5][1].append(current_date)\n",
    "\n",
    "    #Цикл для записи всех дейстрий в матрицу\n",
    "    while current_date < finish_date: \n",
    "        #Инициализация резервуара\n",
    "        rez_stox = np.random.random_integers(0, len(df_for_count_data) - 1)\n",
    "        #Инициализация пистолета\n",
    "        pump_stox = int(df_for_check_data['pump_num'][df_for_check_data['rez_id']==\\\n",
    "                                                      df_for_count_data.loc[rez_stox, 'rez']].sample(n=1))\n",
    "        #Генерация сливов в литрах\n",
    "        check_value = round(np.random.normal(30, 10), 2)\n",
    "\n",
    "        matrix_sliv[rez_stox, 1] = check_value\n",
    "        count_check[rez_stox][0].append(check_value)\n",
    "        count_check[rez_stox][2].append(pump_stox)\n",
    "\n",
    "        parallel_date = count_check[rez_stox][1][-1]\\\n",
    "        + dt.timedelta(seconds=int(np.random.normal(dict_for_data[str(df_for_count_data.loc[0,'rez_volume'])], 10)))\n",
    "        \n",
    "        count_check[rez_stox][1].append(parallel_date)\n",
    "\n",
    "        #Изменение остатков в резервуаре при отпуске клиенту\n",
    "        matrix_sliv[rez_stox, 0] = matrix_sliv[rez_stox, 0] - matrix_sliv[rez_stox, 1]\n",
    "        #Обновление даты\n",
    "        current_date = max([count_check[key][1][-1] for key in count_check.keys() if count_check[key][1]])\n",
    "        \n",
    "        # Условие для изменение бригаде по смене\n",
    "        if current_date > start_shift + dt.timedelta(hours=\\\n",
    "                                                    int(df_for_shift_data.loc[df_for_shift_data[df_for_shift_data['shift_num']==\\\n",
    "                                                                                                shift_num].index[0], 'shift_duration'])):\n",
    "            # Обновление даты начала смены на новую\n",
    "            start_shift = dt.datetime(current_date.year, current_date.month, current_date.day, current_date.hour, 0)\n",
    "            # Запись результата сверки типа 4\n",
    "            matrix_type_4 = np.vstack((matrix_type_4, np.hstack((matrix_sliv[:, 0], shift_num, start_shift-dt.timedelta(seconds=1)))))\n",
    "            shift_num += 1\n",
    "            if shift_num > len(df_for_shift_data.loc[:, 'shift_num']):\n",
    "                shift_num = 1\n",
    "            matrix_shift[count_fact_shift, 2] = start_shift - dt.timedelta(seconds=1)\n",
    "            count_fact_shift += 1\n",
    "            # Запись факта смены бригады\n",
    "            matrix_shift = np.vstack((matrix_shift, [shift_num, start_shift, 0]))\n",
    "            \n",
    "            \n",
    "\n",
    "        #Условие для больших резервуаров\n",
    "        if df_for_count_data.loc[0,'kind_tanker']=='big_tank':\n",
    "            #Условие для приезда АЦ. Если в одном из резервуаров остатки меньше чем 10% или все резервуары можно долить одним приездом АЦ\n",
    "            if any(matrix_sliv[:, 0] <= df_for_count_data.loc[0,'rez_volume']*0.1)\\\n",
    "            or ((matrix_sliv[df_for_count_data[df_for_count_data['oil_type']=='ДТ'].index.item(), 0]\\\n",
    "            <(df_for_count_data.loc[0,'rez_volume']\\\n",
    "            -df_tanker.loc['big_tank', 'diesel'])) and (np.count_nonzero(matrix_sliv[:, 0] < (df_for_count_data.loc[0,'rez_volume']\\\n",
    "            -df_tanker.loc['big_tank', 'diesel']) ) >= 4) and (any(matrix_sliv[:, 0] <= (df_for_count_data.loc[0,'rez_volume']\\\n",
    "            -df_tanker.loc['big_tank', 'petrol1'])))):\n",
    "                #Запись сострояния остатков в переменную\n",
    "                var = matrix_sliv[:, 0].copy()\n",
    "                matrix_sliv[df_for_count_data[df_for_count_data['oil_type'] == 'ДТ'].index.item(), 0] = np.inf\n",
    "                #Цикл который выбирает наименее заполненный резервуар и заполняет его\n",
    "                for i in range(df_tanker.shape[1]-2):\n",
    "                    #Заполение столбца матрицы для слива из АЦ\n",
    "                    matrix_sliv[np.argmin(matrix_sliv[:, 0]), 2] += df_tanker.loc['big_tank', f'petrol{i+1}'] \\\n",
    "                        if (df_for_count_data.loc[0, 'rez_volume'] - matrix_sliv[np.argmin(matrix_sliv[:, 0]), 0]) \\\n",
    "                        > df_tanker.loc['big_tank', f'petrol{i+1}'] else 0\n",
    "                    #Изменеие текущего времени после первого слива из АЦ\n",
    "                    matrix_sliv[np.argmin(matrix_sliv[:, 0]), 4] = current_date + dt.timedelta(seconds=int(np.random.normal(2400, 200)))\n",
    "                    current_date = matrix_sliv[np.argmin(matrix_sliv[:, 0]), 4]\n",
    "                    #Измение остатков резервуара после каждого слива\n",
    "                    matrix_sliv[np.argmin(matrix_sliv[:, 0]), 0] += matrix_sliv[np.argmin(matrix_sliv[:, 0]), 2]\n",
    "                #Возврат состояния резервуара до слива    \n",
    "                matrix_sliv[:, 0] = var\n",
    "                #Заполенеие резервуара с Дизелем\n",
    "                matrix_sliv[df_for_count_data[df_for_count_data['oil_type'] == 'ДТ'].index.item(), 2] = df_tanker.loc['big_tank', 'diesel'] \\\n",
    "                    if (df_for_count_data.loc[0, 'rez_volume'] - matrix_sliv[df_for_count_data[df_for_count_data['oil_type'] == 'ДТ'].index.item(), 0])\\\n",
    "                    > df_tanker.loc['big_tank', 'diesel'] else 0\n",
    "                #Изменеие текущего времени после первого слива из АЦ\n",
    "                matrix_sliv[df_for_count_data[df_for_count_data['oil_type'] == 'ДТ'].index.item(), 4] = current_date +\\\n",
    "                dt.timedelta(seconds=int(np.random.normal(2400, 200)))\n",
    "                current_date = matrix_sliv[df_for_count_data[df_for_count_data['oil_type'] == 'ДТ'].index.item(), 4]\n",
    "\n",
    "            else:\n",
    "                #если не подходит под условию слива переходим к следующей иттерации\n",
    "                continue\n",
    "        #Условие для малых резервуаров\n",
    "        else:\n",
    "            #Условие для приезда АЦ. Если в одном из резервуаров остатки меньше чем 10% или все резервуары можно долить одним приездом АЦ\n",
    "            if any(matrix_sliv[:, 0] <= df_for_count_data.loc[0,'rez_volume']*0.1)\\\n",
    "            or ((matrix_sliv[df_for_count_data[df_for_count_data['oil_type']=='ДТ'].index.item(), 0]\\\n",
    "            <(df_for_count_data.loc[0,'rez_volume']\\\n",
    "            -df_tanker.loc['small_tank', 'diesel'])) and (np.count_nonzero(matrix_sliv[:, 0] < (df_for_count_data.loc[0,'rez_volume']\\\n",
    "            -df_tanker.loc['small_tank', 'diesel'])) >= 3)):\n",
    "                #Запись сострояния остатков в переменную\n",
    "                var = matrix_sliv[:, 0].copy()\n",
    "                matrix_sliv[df_for_count_data[df_for_count_data['oil_type'] == 'ДТ'].index.item(), 0] = np.inf\n",
    "                #Цикл который выбирает наименее заполненный резервуар и заполняет его\n",
    "                for i in range(df_tanker.shape[1]-3):\n",
    "                    matrix_sliv[np.argmin(matrix_sliv[:, 0]), 2] += df_tanker.loc['small_tank', f'petrol{i+1}'] \\\n",
    "                        if (df_for_count_data.loc[0, 'rez_volume'] - matrix_sliv[np.argmin(matrix_sliv[:, 0]), 0]) \\\n",
    "                        > df_tanker.loc['small_tank', f'petrol{i+1}'] else 0\n",
    "                    #Изменеие текущего времени после первого слива из АЦ\n",
    "                    matrix_sliv[np.argmin(matrix_sliv[:, 0]), 4] = current_date + dt.timedelta(seconds=int(np.random.normal(2400, 200)))\n",
    "                    current_date = matrix_sliv[np.argmin(matrix_sliv[:, 0]), 4]\n",
    "                    #Измение остатков резервуара после каждого слива\n",
    "                    matrix_sliv[np.argmin(matrix_sliv[:, 0]), 0] += matrix_sliv[np.argmin(matrix_sliv[:, 0]), 2]\n",
    "                #Возврат состояния резервуара до слива     \n",
    "                matrix_sliv[:, 0] = var\n",
    "                #Заполенеие резервуара с Дизелем\n",
    "                matrix_sliv[df_for_count_data[df_for_count_data['oil_type'] == 'ДТ'].index.item(), 2] = df_tanker.loc['small_tank', 'diesel'] \\\n",
    "                    if (df_for_count_data.loc[0, 'rez_volume'] - matrix_sliv[df_for_count_data[df_for_count_data['oil_type'] == 'ДТ'].index.item(), 0])\\\n",
    "                    > df_tanker.loc['small_tank', 'diesel'] else 0\n",
    "                #Изменеие текущего времени после первого слива из АЦ\n",
    "                matrix_sliv[df_for_count_data[df_for_count_data['oil_type'] == 'ДТ'].index.item(), 4] = current_date +\\\n",
    "                dt.timedelta(seconds=int(np.random.normal(2400, 200)))\n",
    "                current_date = matrix_sliv[df_for_count_data[df_for_count_data['oil_type'] == 'ДТ'].index.item(), 4]\n",
    "            else:\n",
    "                #если не подходит под условию слива переходим к следующей иттерации\n",
    "                continue\n",
    "                \n",
    "        #Записываем результаты после слива из АЦ в столбец матрицы       \n",
    "        matrix_sliv[:,3] = matrix_sliv[:,0] + matrix_sliv[:,2]\n",
    "        #Цикл для записи только тех случаев где был слив\n",
    "        for key, value in matrix_dict.items():\n",
    "            if 0 in matrix_sliv[key, [0,2,3,4]]:\n",
    "                continue\n",
    "            matrix_dict[key] = np.vstack((np.array(value), matrix_sliv[key, [0,2,3,4]])).tolist()\n",
    "        # Обновление остатков в резервуаре\n",
    "        matrix_sliv[:,0] = matrix_sliv[:,3]\n",
    "        \n",
    "        # Условие для изменение бригаде по смене\n",
    "        if current_date > start_shift + dt.timedelta(hours=\\\n",
    "                                                    int(df_for_shift_data.loc[df_for_shift_data[df_for_shift_data['shift_num']==\\\n",
    "                                                                                                shift_num].index[0], 'shift_duration'])):\n",
    "            # Обновление даты начала смены на новую\n",
    "            start_shift = dt.datetime(current_date.year, current_date.month, current_date.day, current_date.hour, current_date.second)\\\n",
    "            +dt.timedelta(seconds=2)\n",
    "            # Запись результата сверки типа 4\n",
    "            matrix_type_4 = np.vstack((matrix_type_4, np.hstack((matrix_sliv[:, 0], shift_num, start_shift- dt.timedelta(seconds=1)))))\n",
    "            shift_num += 1\n",
    "            if shift_num > len(df_for_shift_data.loc[:, 'shift_num']):\n",
    "                shift_num = 1\n",
    "            matrix_shift[count_fact_shift, 2] = start_shift\n",
    "            count_fact_shift += 1\n",
    "            # Запись факта смены бригады\n",
    "            matrix_shift = np.vstack((matrix_shift, [shift_num, start_shift, 0]))\n",
    "        \n",
    "        matrix_sliv[:,2] = 0\n",
    "        #Инициализация нового состояния времени\n",
    "        count_check[0][1].append(current_date)\n",
    "        count_check[1][1].append(current_date)\n",
    "        count_check[2][1].append(current_date)\n",
    "        count_check[3][1].append(current_date)\n",
    "        count_check[4][1].append(current_date)\n",
    "        count_check[5][1].append(current_date)\n",
    "\n",
    "    # Запись нового словарика без начального состояния     \n",
    "    matrix_dict_for_note = {key: value[1:] for key, value in matrix_dict.items()}\n",
    "\n",
    "    #Функция для удаления из чеков дат по сливам из АЦ\n",
    "    def clean_data_for_check(count_check):\n",
    "        for key in count_check.keys():\n",
    "            count_check[key][1] = [x for x in count_check[key][1] if x not in count_check[5][1]]\n",
    "        return count_check\n",
    "    #Применение функции\n",
    "    dict_for_check = clean_data_for_check(count_check)\n",
    "    \n",
    "    # Очистка первого и последнего столбца из расписания смен\n",
    "    matrix_fact = matrix_shift[1:-1, :]\n",
    "    # Очистка первого столбца из матрицы сверки номер 4\n",
    "    matrix_type_4 = matrix_type_4[1:, :]\n",
    "    \n",
    "    \n",
    "    #Функция для формирования таблицы из слованика сливов из АЦ\n",
    "    def prepare_table_for_note(matrix_dict_for_note, df_for_count_data):\n",
    "        #Цикл для удаления нулевых значений из словарика\n",
    "        for key in matrix_dict_for_note.keys():\n",
    "            matrix_dict_for_note[key] = [elem for elem in matrix_dict_for_note[key] if elem != 0]\n",
    "        #Формирование дата фрейма с нужными столбцами\n",
    "        df_for_note = pd.DataFrame(columns=df_for_count_data.columns.values.tolist()[:-2]+['rest', 'fuel', 'actual_weight', 'document_date'])\n",
    "        i = 0\n",
    "        #Цикл для записи данных в новый датафрейм из таблицы НСИ и матрицы\n",
    "        for key in matrix_dict_for_note.keys():\n",
    "            for value in range(len(matrix_dict_for_note[key])):\n",
    "                df_for_note.loc[i,'pnpo'] = df_for_count_data.loc[key, 'pnpo']\n",
    "                df_for_note.loc[i,'azs'] = df_for_count_data.loc[key, 'azs']\n",
    "                df_for_note.loc[i,'rez_volume'] = df_for_count_data.loc[key, 'rez_volume']\n",
    "                df_for_note.loc[i,'rez'] = df_for_count_data.loc[key, 'rez']\n",
    "                df_for_note.loc[i,'oil_id'] = df_for_count_data.loc[key, 'oil_id']\n",
    "                df_for_note.loc[i,'rest'] = matrix_dict_for_note[key][value][0]\n",
    "                df_for_note.loc[i,'fuel'] = matrix_dict_for_note[key][value][1]\n",
    "                df_for_note.loc[i,'actual_weight'] = matrix_dict_for_note[key][value][2]\n",
    "                df_for_note.loc[i,'document_date'] = matrix_dict_for_note[key][value][3]\n",
    "                i += 1\n",
    "        return df_for_note\n",
    "    #Применение функции\n",
    "    df_for_note = prepare_table_for_note(matrix_dict_for_note, df_for_count_data)\n",
    "\n",
    "    #Функция для внесения дебалансов\n",
    "    def form_debalance(df_for_note, mutual_part_for_noise, positive_part_for_noise,\\\n",
    "                       left_positive_border, right_positive_border, left_negative_border, right_negative_border):\n",
    "        range_positive_noise = [left_positive_border, right_positive_border]\n",
    "        range_negative_noise = [left_negative_border, right_negative_border]\n",
    "        negative_part_for_noise = 1 - positive_part_for_noise\n",
    "        range_negative_noise = [-1 * val for val in range_negative_noise]\n",
    "        range_massive = [range_positive_noise, range_negative_noise]\n",
    "        range_part_noise = [positive_part_for_noise, negative_part_for_noise]\n",
    "        #Формирование значений которые будут с дебалансов случайным образом\n",
    "        df_sample = df_for_note.sample(frac=mutual_part_for_noise)\n",
    "        #Добавление столбца с меткой о том каким будет отклонение\n",
    "        df_sample['mask_deviation'] = [np.random.choice([0, 1], p=range_part_noise)\\\n",
    "                                      for _ in range(len(df_sample))]\n",
    "        #Расчет отклонений\n",
    "        df_sample['actual_weight'] = [df_sample.loc[i,'actual_weight']\\\n",
    "        + df_sample.loc[i,'actual_weight']*np.random.uniform(low=range_massive[0][0],\\\n",
    "                                 high=range_massive[0][1]) if df_sample.loc[i,'mask_deviation']==0\n",
    "        else df_sample.loc[i,'actual_weight']\\\n",
    "                                            + df_sample.loc[i,'actual_weight']*np.random.uniform(low=range_massive[1][0],\\\n",
    "                                 high=range_massive[1][1]) for i in df_sample.index]\n",
    "        #Формирование нового столбца и расчет дебалансов в нем\n",
    "        df_for_note['measured_weight'] = [round(df_sample.loc[i, 'actual_weight'], 2)\\\n",
    "                                          if i in df_sample.index else df_for_note.loc[i, 'actual_weight'] \n",
    "                                          for i in df_for_note.index]\n",
    "        return df_for_note\n",
    "    #Применение функции\n",
    "    df_with_debalance = form_debalance(df_for_note, mutual_part_for_noise, positive_part_for_noise,\\\n",
    "                           left_positive_border, right_positive_border, left_negative_border, right_negative_border)\n",
    "\n",
    "    \n",
    "    # Функция для подготовки датафрейма по сверке типа 4\n",
    "    def prepare_df_type_4(matrix_type_4, df_for_count_data):\n",
    "        i = 0\n",
    "        df_type_4 = pd.DataFrame()\n",
    "        for m in range(matrix_type_4.shape[0]):\n",
    "            for n in range(len(df_for_count_data)):\n",
    "                df_type_4.loc[i, 'actual_weight'] = matrix_type_4[m, n]\n",
    "                df_type_4.loc[i, 'shift_num'] = matrix_type_4[m, len(df_for_count_data)]\n",
    "                df_type_4.loc[i, 'document_date'] = matrix_type_4[m, len(df_for_count_data) + 1]\n",
    "                df_type_4.loc[i, 'rez_id'] = df_for_count_data.loc[n, 'rez']\n",
    "                i+=1\n",
    "        return df_type_4\n",
    "    df_type_4 = prepare_df_type_4(matrix_type_4, df_for_count_data)\n",
    "    \n",
    "    # Функция для подготовки датафрейма по сливам из пистолетов\n",
    "    def prepare_df_checks(dict_for_check, df_pump):\n",
    "        lst = []\n",
    "        for key, values in dict_for_check.items():\n",
    "            for i in range(len(values[0])):\n",
    "                lst.append({'volume': values[0][i], 'datetime': values[1][i],\\\n",
    "                            'pump_id' : df_pump.loc[df_pump[(df_pump['azs_id'] == azs_name)\\\n",
    "                                                            & (df_pump['pump_num']==values[2][i])].index[0], 'pump_id']})\n",
    "        df_checks = pd.DataFrame(lst)\n",
    "        return df_checks\n",
    "    df_checks = prepare_df_checks(dict_for_check, df_pump)\n",
    "    \n",
    "    # Функция для подготовки датафрейма по графику смен\n",
    "    def prepare_shift_fact(matrix_fact, df_shift):\n",
    "        df_shift_fact = pd.DataFrame(matrix_fact, columns=['shift_id', 'start_time', 'end_time'])\n",
    "        df_shift_fact['shift_id'] = [df_shift['shift_id'][(df_shift['azs_id']==azs_name) \\\n",
    "                 & (df_shift['shift_num']==df_shift_fact.loc[i, 'shift_id'])].values[0] for i in range(len(df_shift_fact))]\n",
    "        return df_shift_fact\n",
    "    \n",
    "    df_shift_fact = prepare_shift_fact(matrix_fact, df_shift)\n",
    "    \n",
    "    #Функция для загрузки данных в таблицу\n",
    "    def load_generate_data_to_bd(df_with_debalance, df_checks, df_type_4, df_shift_fact):\n",
    "        #Переименование столбцов\n",
    "        df_for_load_generate_data = df_with_debalance[['pnpo', 'azs', 'rez', 'oil_id',\\\n",
    "                                                       'rest', 'fuel', 'actual_weight', 'document_date', 'measured_weight']]\n",
    "        df_for_load_generate_data.columns = ['pnpo_id', 'azs_id', 'rez_id', 'oil_id',\\\n",
    "                                            'remaining_fuel', 'draining_fuel', 'actual_weight', 'document_date', 'measured_weight']\n",
    "        #Смена типа для столбцов с внешними ключами\n",
    "        df_for_load_generate_data['pnpo_id'] = df_for_load_generate_data['pnpo_id'].astype(int)\n",
    "        df_for_load_generate_data['azs_id'] = df_for_load_generate_data['azs_id'].astype(int)\n",
    "        df_for_load_generate_data['rez_id'] = df_for_load_generate_data['rez_id'].astype(int)\n",
    "        df_for_load_generate_data['oil_id'] = df_for_load_generate_data['oil_id'].astype(int)\n",
    "        df_for_load_generate_data['remaining_fuel'] = df_for_load_generate_data['remaining_fuel'].astype(float)\n",
    "        df_for_load_generate_data['draining_fuel'] = df_for_load_generate_data['draining_fuel'].astype(float)\n",
    "        df_for_load_generate_data['actual_weight'] = df_for_load_generate_data['actual_weight'].astype(float)\n",
    "        \n",
    "        # Импорт парметров подключения к БД\n",
    "        from config import database\n",
    "\n",
    "        #Подключение к БД\n",
    "        conn = db.connect(**database)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        engine = create_engine('postgresql+psycopg2://{user}:{password}@{host}:5432/{database}'.format(**database))\n",
    "\n",
    "        df_for_load_generate_data.to_sql('cp01_sintetic_data', engine, if_exists='append', index=False, schema='superset')\n",
    "        df_shift_fact.to_sql('shift_fact', engine, if_exists='append', index=False, schema='superset')\n",
    "        df_type_4.to_sql('revice4', engine, if_exists='append', index=False, schema='superset')\n",
    "        df_checks.to_sql('check_goods', engine, if_exists='append', index=False, schema='superset')\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "        return print('По АЗС №', azs_name,'Данные успешно загружены')\n",
    "    #Применение функции\n",
    "    finish = load_generate_data_to_bd(df_with_debalance, df_checks, df_type_4, df_shift_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40135412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
